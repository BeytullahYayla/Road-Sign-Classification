# -*- coding: utf-8 -*-
"""Classifying Road Symbols.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/BeytullahYayla/Computer-Vision-For-Self-Driving-Cars/blob/main/Classifying%20Road%20Symbols/Classifying_Road_Symbols.ipynb
"""



from tensorflow.keras.optimizers import Adam
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.utils.np_utils import to_categorical
from keras.layers import Dropout, Flatten
from keras.layers.convolutional import Conv2D, MaxPooling2D
import pickle
import pandas as pd
import random 
np.random.seed(0)

!git clone https://bitbucket.org/jadslim/german-traffic-signs

!ls german-traffic-signs

!pip install keras

with open('german-traffic-signs/train.p','rb') as f:
  train_data=pickle.load(f)
with open('german-traffic-signs/valid.p','rb') as f:
  valid_data=pickle.load(f)
with open('german-traffic-signs/test.p','rb') as f:
  test_data=pickle.load(f)

print(type(train_data))
X_train,y_train=train_data["features"],train_data["labels"]
X_val,y_val=valid_data["features"],valid_data["labels"]
X_test,y_test=test_data["features"],test_data["labels"]

print(X_train.shape)
print(X_val.shape)
print(X_test.shape)

assert(X_train.shape[0]==y_train.shape[0]), "The number of images is not equal to the number of labels"
assert(X_val.shape[0]==y_val.shape[0]),"The number of images is not equal to the number of labels"
assert(X_test.shape[0]==y_test.shape[0]),"The number of images is not equal to the number of labels"
assert(X_train.shape[1:]==(32,32,3)),"The dimensions of the images are not 32x32x3"
assert(X_val.shape[1:]==(32,32,3)),"The dimensions of the images are not 32x32x3"
assert(X_test.shape[1:]==(32,32,3)),"The dimensions of the images are not 32x32x3"

data=pd.read_csv('german-traffic-signs/signnames.csv')
data

num_of_samples=[]


cols=5
num_classes=43

fig,axs=plt.subplots(nrows=num_classes,ncols=cols,figsize=(5,50))
fig.tight_layout()

for i in range(cols):
  for j,row in data.iterrows():
    x_selected=X_train[y_train==j]
    axs[j][i].imshow(x_selected[random.randint(0,len(x_selected)-1),:,:],cmap=plt.get_cmap('gray'))
    axs[j][i].axis("off")
    if i==2:
      axs[j][i].set_title(str(j)+"-"+row["SignName"])
      num_of_samples.append(len(x_selected))

print(num_of_samples)
plt.figure(figsize=(12,4))
plt.bar(range(0,num_classes),num_of_samples)
plt.title("Distrubution of the train set")
plt.xlabel("Class number")
plt.ylabel("Number of images")
plt.show()

import cv2

def cvrt_grayscale(img):
  img=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)
  return img

img=cvrt_grayscale(X_train[1000])
print(img.shape)
plt.imshow(img);
plt.axis("off")

def equalize(img):
  img=cv2.equalizeHist(img)
  return img
img=equalize(img)
plt.imshow(img)

def preprocessing(img):
  grayscale_image=cvrt_grayscale(img)
  equalized_image=equalize(grayscale_image)
  normalized_image=equalized_image/255
  return equalized_image

X_train=np.array(list(map(preprocessing,X_train)))
X_val=np.array(list(map(preprocessing,X_val)))
X_test=np.array(list(map(preprocessing,X_test)))

plt.imshow(X_train[random.randint(0,len(X_train)-1)])
print(X_train.shape)

X_train=X_train.reshape(34799, 32, 32,1)
X_val=X_val.reshape(4410,32,32,1)
X_test=X_test.reshape(12630,32,32,1)

from keras.preprocessing.image import ImageDataGenerator

datagen=ImageDataGenerator(width_shift_range=0.1,
                           height_shift_range=0.1,
                           shear_range=10,
                           zoom_range=0.2,
                           rotation_range=10
                           )
datagen.fit(X_train)#We apply augmentation on X_train

batches=datagen.flow(X_train,y_train,batch_size=15)
X_batch,y_batch=next(batches)
fig,axs,=plt.subplots(1,15,figsize=(20,5))
fig.tight_layout()

print("Augmented Images")

for i in range(15):
  axs[i].imshow(X_batch[i].reshape(32,32))
  axs[i].axis("off")

print(X_train.shape)
print(X_val.shape)
print(X_test.shape)

y_train=to_categorical(y_train,43)
y_val=to_categorical(y_val,43)
y_test=to_categorical(y_test,43)

"""## Lenet Implementation"""

def modified_model():
  #Building the model
  model = Sequential()
  model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape = (32,32,1)))
  model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))
  model.add(MaxPooling2D(pool_size=(2, 2)))
  model.add(Dropout(rate=0.25))
  model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))
  model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))
  model.add(MaxPooling2D(pool_size=(2, 2)))
  model.add(Dropout(rate=0.25))
  model.add(Flatten())
  model.add(Dense(256, activation='relu'))
  model.add(Dropout(rate=0.5))
  model.add(Dense(43, activation='softmax'))
#Compilation of the model
  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
  return model

model = modified_model()
print(model.summary())

eps = 15
anc = model.fit(X_train, y_train, batch_size=32, epochs=eps, validation_data=(X_val, y_val))

plt.plot(anc.history["loss"])
plt.plot(anc.history["val_loss"])
plt.legend(['training','validation'])
plt.xlabel(" Epoch")
plt.ylabel("Loss")

plt.plot(anc.history['accuracy'])
plt.plot(anc.history["val_accuracy"])
plt.legend(['training','validation'])
plt.xlabel(" Epoch")
plt.ylabel("Accuracy")

import requests
from PIL import Image
url = 'https://previews.123rf.com/images/bwylezich/bwylezich1608/bwylezich160800375/64914157-german-road-sign-slippery-road.jpg'
r = requests.get(url, stream=True)
img = Image.open(r.raw)
plt.imshow(img, cmap=plt.get_cmap('gray'))

img = np.asarray(img)
img = cv2.resize(img, (32, 32))
img = preprocessing(img)
plt.imshow(img, cmap = plt.get_cmap('gray'))
print(img.shape)

img = img.reshape(1, 32, 32, 1)

predicted_image=model.predict(img)
predicted_class=np.argmax(predicted_image,axis=1)
print("predicted sign: "+ str(predicted_class))